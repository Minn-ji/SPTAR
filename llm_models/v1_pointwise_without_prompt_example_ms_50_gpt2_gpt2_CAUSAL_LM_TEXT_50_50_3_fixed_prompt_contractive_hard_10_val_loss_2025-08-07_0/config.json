{
  "device": "cpu",
  "device_idx": "1",
  "llm_name": "gpt2",
  "model_name_or_path": "openai-community/gpt2",
  "tokenizer_name_or_path": "openai-community/gpt2",
  "peft_type": "CAUSAL_LM",
  "task_type": "TEXT",
  "num_virtual_tokens": 50,
  "prompt_tuning_init_text": "please generate query for this document",
  "peft_model_id": "gpt2_CAUSAL_LM_TEXT",
  "prompt_num": 3,
  "text_len": 1024,
  "dataset_name": "ms_50",
  "train_data": "xuyang/data/msmarco_50/prompt_tuning_50_train_text.csv",
  "eval_data": "xuyang/data/msmarco_50/prompt_tuning_50_test_text.csv",
  "test_data": "xuyang/data/msmarco_50/prompt_tuning_50_test_text.csv",
  "few_shot_num": 50,
  "fixed_prompt": true,
  "max_length": 1024,
  "lr": 0.03,
  "num_epochs": 1,
  "batch_size": 1,
  "eval_batch_size": 2,
  "checkpoint_name": "ms_50_openai-community_gpt2_CAUSAL_LM_TEXT_v1.pt",
  "experiment_dir": "llm_models",
  "experiment_description": "v1_pointwise_without_prompt_example_ms_50_gpt2_gpt2_CAUSAL_LM_TEXT_50_50_3_fixed_prompt_contractive_hard_10_val_loss"
}